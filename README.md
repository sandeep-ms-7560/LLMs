# 🧠 LLM Code Examples by Sandeep M S

Welcome to my repository of **Large Language Model (LLM)** code examples, designed to demonstrate practical applications, experiments, and learning exercises related to modern generative AI. This repository serves as a hands-on portfolio of my journey in mastering LLMs, covering foundational concepts to advanced usage.

---

## 🚀 What's Inside

This repository includes code snippets, mini-projects, and notebooks that showcase:

- ✅ Prompt engineering techniques
- ✅ Few-shot and zero-shot examples
- ✅ Text summarization, classification, and Q&A using LLMs
- ✅ Fine-tuning small language models (e.g., LLaMA, Falcon, Mistral)
- ✅ Running models locally using tools like **Ollama**, **Transformers**, and **LangChain**
- ✅ Building simple LLM-powered applications (chatbots, agents, etc.)
- ✅ Evaluating and benchmarking LLM performance

---

## 🧰 Tools & Frameworks Used

- Python
- Hugging Face Transformers
- LangChain
- Ollama (for local LLMs)
- OpenAI API / LLaMA / Mistral
- Streamlit / Gradio (for quick demos)
- Weights & Biases (for tracking experiments)

---

## 📁 Repository Structure

```bash
.
├── prompts/              # Prompt engineering examples
├── applications/         # LLM-based mini-projects and tools
├── local_llms/           # Run and test local LLMs (Ollama, etc.)
├── finetuning/           # Fine-tuning experiments and scripts
├── notebooks/            # Jupyter notebooks for EDA and experimentation
└── utils/                # Common helper functions
